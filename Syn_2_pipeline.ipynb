{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from composite import *\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import shutil\n",
    "from sahi.utils.file import load_json, save_json\n",
    "from sahi.utils.coco import Coco, CocoCategory, CocoImage, CocoAnnotation, merge_from_list\n",
    "from sahi.utils.cv import get_coco_segmentation_from_bool_mask, get_bbox_from_bool_mask\n",
    "from sklearn.model_selection import GroupKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load image path as well as annotations based on which we want to generate more synthetic defect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"./Datasets/ps5_dataset/images/\"\n",
    "annotation_file = \"./Datasets/ps5_dataset/ps5_annotations.json\"\n",
    "with open(annotation_file, 'r') as f:\n",
    "    annotations = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The structure of the json annotation file is as follows:\n",
    "{\n",
    "    image_name: [\n",
    "        {\n",
    "            bbox: [x, y, w, h],  # bounding box coordinate\n",
    "            seg1: [[x1, y1, x2, y2, ...], [x1, y1, x2, y2, ...], ...],  # polygon annotation from annotator 1, can have multiple polygons\n",
    "            seg2: [[x1, y1, x2, y2, ...], [x1, y1, x2, y2, ...], ...],  # polygon annotation from annotator 2, can have multiple polygons\n",
    "            category: a string representing defect category\n",
    "        },\n",
    "        ...\n",
    "    ]  # list of defect annotations\n",
    "}\n",
    "\n",
    "Note: either or both of seg1 and seg2 annotation could be empty for some defects that are hard to identify from image alone, we can choose to ignore these defects for now\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Training and test (val) split. \n",
    "In the augmentation process, we will only augment the training set and test on the same validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the annotation masks from the two annotators \n",
    "cat_id = {'Collision': 0, 'Dirty': 1, 'Scratch': 2}\n",
    "rows = []\n",
    "defect_id = 0\n",
    "images = sorted(list(annotations.keys()))\n",
    "for image_id, image_name in enumerate(images):\n",
    "    image = Image.open(os.path.join(image_path, image_name)).convert('RGB')\n",
    "    defects = annotations[image_name]\n",
    "    for defect in defects:\n",
    "        mask = np.zeros((image.height, image.width)).astype(np.uint8)\n",
    "        seg1 = [np.array(poly) for poly in defect['seg1']]\n",
    "        mask = cv2.fillPoly(mask, seg1, 255, lineType=cv2.LINE_AA)\n",
    "        # visualize annotator 2 polygons in blue channel\n",
    "        seg2 = [np.array(poly) for poly in defect['seg2']]\n",
    "        mask = cv2.fillPoly(mask, seg2, 255, lineType=cv2.LINE_AA)\n",
    "        rows.append({\n",
    "            'defect_id': defect_id,\n",
    "            'image_id': image_id,\n",
    "            'image_name':image_name, # I added a image name\n",
    "            'category': defect['category'],\n",
    "            'category_id': cat_id[defect['category']],\n",
    "            'bbox': get_bbox_from_bool_mask(mask),\n",
    "            'seg': get_coco_segmentation_from_bool_mask(mask),\n",
    "        })\n",
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratefied data split over defect types\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "train, valid = next(gkf.split(df.defect_id, df.category_id, groups=df.image_id))\n",
    "print(\"%s %s\" % (len(train), len(valid)))\n",
    "train_imgs = df.iloc[train]['image_name'].unique()\n",
    "valid_imgs = df.iloc[valid]['image_name'].unique()\n",
    "print(train_imgs)\n",
    "print(valid_imgs)\n",
    "assert set(train_imgs).isdisjoint(valid_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1  Save a raw the training and validation sets as a baseline\n",
    "The save path is ```'./Raw_dataset/ps5_seg_coco/'```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Coco Style Annotation with Sahi\n",
    "data_path = './Raw_dataset/ps5_seg_coco/'\n",
    "os.makedirs(data_path, exist_ok= True)\n",
    "coco_train = Coco()\n",
    "coco_valid = Coco()\n",
    "\n",
    "for category, i in cat_id.items():\n",
    "    coco_train.add_category(CocoCategory(id=i, name=category))\n",
    "    coco_valid.add_category(CocoCategory(id=i, name=category))\n",
    "\n",
    "for image_id, image_name in enumerate(images):\n",
    "    image = Image.open(os.path.join(image_path, image_name)).convert('RGB')\n",
    "    coco_image = CocoImage(file_name=image_name, height=image.height, width=image.width)\n",
    "\n",
    "    defects = df[df.image_name == image_name]\n",
    "    for _, defect in defects.iterrows():\n",
    "        # print(defect.bbox, defect.seg, defect.category_id, defect.category)\n",
    "        if defect.bbox:\n",
    "            coco_image.add_annotation(\n",
    "                CocoAnnotation(\n",
    "                    bbox=defect.bbox,\n",
    "                    segmentation=defect.seg,\n",
    "                    category_id=defect.category_id,\n",
    "                    category_name=defect.category\n",
    "                )\n",
    "            )\n",
    "    if image_name in train_imgs:\n",
    "        shutil.copy(os.path.join(image_path, image_name), os.path.join(data_path, 'train', image_name))\n",
    "        coco_train.add_image(coco_image)\n",
    "    elif image_name in valid_imgs:\n",
    "        shutil.copy(os.path.join(image_path, image_name), os.path.join(data_path, 'valid', image_name))\n",
    "        coco_valid.add_image(coco_image)\n",
    "print(coco_train.stats[\"num_annotations_per_category\"])\n",
    "print(coco_valid.stats[\"num_annotations_per_category\"])\n",
    "save_json(coco_train.json, os.path.join(data_path, 'train', '_annotations.coco.json'))\n",
    "save_json(coco_valid.json, os.path.join(data_path, 'valid', '_annotations.coco.json'))\n",
    "\n",
    "# Create Sliced Datasets with Sahi\n",
    "from sahi.slicing import slice_coco\n",
    "from sahi.utils.file import load_json, save_json\n",
    "\n",
    "\n",
    "data_path = './Raw_dataset/ps5_seg_coco/'\n",
    "slice_path = './Raw_dataset/ps5_sliced/'\n",
    "train_sliced_coco_dict, _ = slice_coco(\n",
    "    coco_annotation_file_path=os.path.join(data_path, 'train', '_annotations.coco.json'),\n",
    "    image_dir=os.path.join(data_path, 'train'),\n",
    "    output_coco_annotation_file_name=None,\n",
    "    ignore_negative_samples=False,\n",
    "    output_dir=os.path.join(slice_path, 'train'),\n",
    "    slice_height=512,\n",
    "    slice_width=512,\n",
    "    overlap_height_ratio=0.2,\n",
    "    overlap_width_ratio=0.2,\n",
    "    min_area_ratio=0.1,\n",
    "    verbose=False\n",
    ")\n",
    "save_json(train_sliced_coco_dict, os.path.join(slice_path, 'train', '_annotations.coco.json'))\n",
    "\n",
    "\n",
    "valid_sliced_coco_dict, _ = slice_coco(\n",
    "    coco_annotation_file_path=os.path.join(data_path, 'valid', '_annotations.coco.json'),\n",
    "    image_dir=os.path.join(data_path, 'valid'),\n",
    "    output_coco_annotation_file_name=None,\n",
    "    ignore_negative_samples=False,\n",
    "    output_dir=os.path.join(slice_path, 'valid'),\n",
    "    slice_height=512,\n",
    "    slice_width=512,\n",
    "    overlap_height_ratio=0.2,\n",
    "    overlap_width_ratio=0.2,\n",
    "    min_area_ratio=0.1,\n",
    "    verbose=False\n",
    ")\n",
    "save_json(valid_sliced_coco_dict, os.path.join(slice_path, 'valid', '_annotations.coco.json'))\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Syntehtic defect generation \n",
    "We will augment the TRAINING set by the following steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = './Augment_result/'+'ps5_dataset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Get defect from the training set and save them in ```output_defect_source_dir``` which is ```work_dir/training_defect_sources/```\n",
    "Move the target defect into the middle of the image to facilitate image augmentation in the next step\n",
    "1. images are saved in the ```work_dir/training_defect_sources/``` \n",
    "2. the defect annotation file is saved as ```work_dir/training_defect_sources/training_defect_library_annotations.json```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_defect_source_dir = work_dir +'training_defect_sources/'\n",
    "defect_source_prep(image_path, train_imgs, annotations, output_defect_source_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Augment defects from \"output_defect_source_dir\" and save them in \"augmented_defect_dir\"\n",
    "Augment the defect using operations from ```albumentations``` package\n",
    "1. images are saved in the ```work_dir/augmented_defect_library/``` \n",
    "2. the defect annotation file is saved as ```work_dir/training_defect_sources/augmented_training_defect_library_annotations.json```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment defects from \"output_defect_source_dir\" and save as \"augmented_defect_dir\"\n",
    "defects_path = output_defect_source_dir\n",
    "defect_annotation_file = output_defect_source_dir+'training_defect_library_annotations.json'\n",
    "augmented_defect_dir = work_dir +'augmented_defect_library/'\n",
    "augment(defects_path, defect_annotation_file, augmented_defect_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Generate the synthetic defect dataset (training set) and save them in \"output_path\"\n",
    "Sample from backgrounds ```input_background_images_list``` and sample defects from ```defects_path```, seamlessly merge thme together.\n",
    "1. images are saved in the ```work_dir+'augmented_training_set/'``` \n",
    "2. the defect annotation file is saved as ```work_dir/training_defect_sources/'generated_training_images_annotation.json```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defects\n",
    "defects_path = augmented_defect_dir\n",
    "# defect_annotations \n",
    "defect_annotation_file = defects_path+'augmented_training_defect_library_annotations.json'\n",
    "output_path = work_dir+'augmented_training_set/'\n",
    "input_background_images_list = train_imgs\n",
    "input_image_annotation = annotations # annotation for the background images, use [] if background is clean\n",
    "generate_new_dataset(image_path, input_background_images_list, input_image_annotation, defects_path, defect_annotation_file, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 change 'generated_training_images_annotation.json' to coco format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image path as well as annotations based on which we want to generate more synthetic defect\n",
    "work_dir = './Augment_result/'+'ps5_dataset/'\n",
    "output_path = work_dir+'augmented_training_set/'\n",
    "defect_annotation_file = output_path + 'generated_training_images_annotation.json'\n",
    "\n",
    "image_path = output_path\n",
    "annotation_file = defect_annotation_file \n",
    "with open(annotation_file, 'r') as f:\n",
    "    annotations = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the annotation masks from the two annotators \n",
    "cat_id = {'Collision': 0, 'Dirty': 1, 'Scratch': 2}\n",
    "rows = []\n",
    "defect_id = 0\n",
    "images = sorted(list(annotations.keys()))\n",
    "for image_id, image_name in enumerate(images):\n",
    "    image = Image.open(os.path.join(image_path, image_name)).convert('RGB')\n",
    "    defects = annotations[image_name]\n",
    "    for defect in defects:\n",
    "        mask = np.zeros((image.height, image.width)).astype(np.uint8)\n",
    "        seg1 = [np.array(poly) for poly in defect['seg1']]\n",
    "        mask = cv2.fillPoly(mask, seg1, 255, lineType=cv2.LINE_AA)\n",
    "        # # visualize annotator 2 polygons in blue channel # I just ignored seg2\n",
    "        # seg2 = [np.array(poly) for poly in defect['seg2']]\n",
    "        # mask = cv2.fillPoly(mask, seg2, 255, lineType=cv2.LINE_AA)\n",
    "        rows.append({\n",
    "            'defect_id': defect_id,\n",
    "            'image_id': image_id,\n",
    "            'image_name':image_name, # I added a image name\n",
    "            'category': defect['category'],\n",
    "            'category_id': cat_id[defect['category']],\n",
    "            'bbox': get_bbox_from_bool_mask(mask),\n",
    "            'seg': get_coco_segmentation_from_bool_mask(mask),\n",
    "        })\n",
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = sorted(list(annotations.keys()))\n",
    "val_imges = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Coco Style Annotation with Sahi\n",
    "data_path = work_dir + 'ps5_seg_coco/'\n",
    "coco_train = Coco()\n",
    "coco_valid = Coco()\n",
    "\n",
    "for category, i in cat_id.items():\n",
    "    coco_train.add_category(CocoCategory(id=i, name=category))\n",
    "    coco_valid.add_category(CocoCategory(id=i, name=category))\n",
    "\n",
    "for image_id, image_name in enumerate(images):\n",
    "    image = Image.open(os.path.join(image_path, image_name)).convert('RGB')\n",
    "    coco_image = CocoImage(file_name=image_name, height=image.height, width=image.width)\n",
    "\n",
    "    defects = df[df.image_name == image_name]\n",
    "    for _, defect in defects.iterrows():\n",
    "        # print(defect.bbox, defect.seg, defect.category_id, defect.category)\n",
    "        if defect.bbox:\n",
    "            coco_image.add_annotation(\n",
    "                CocoAnnotation(\n",
    "                    bbox=defect.bbox,\n",
    "                    segmentation=defect.seg,\n",
    "                    category_id=defect.category_id,\n",
    "                    category_name=defect.category\n",
    "                )\n",
    "            )\n",
    "    if image_name in train_imgs:\n",
    "        shutil.copy(os.path.join(image_path, image_name), os.path.join(data_path, 'train', image_name))\n",
    "        coco_train.add_image(coco_image)\n",
    "print(coco_train.stats[\"num_annotations_per_category\"])\n",
    "save_json(coco_train.json, os.path.join(data_path, 'train', '_annotations.coco.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Sliced Datasets with Sahi\n",
    "from sahi.slicing import slice_coco\n",
    "from sahi.utils.file import load_json, save_json\n",
    "\n",
    "\n",
    "data_path = work_dir + 'ps5_seg_coco/'\n",
    "slice_path = work_dir + 'ps5_sliced/'\n",
    "train_sliced_coco_dict, _ = slice_coco(\n",
    "    coco_annotation_file_path=os.path.join(data_path, 'train', '_annotations.coco.json'),\n",
    "    image_dir=os.path.join(data_path, 'train'),\n",
    "    output_coco_annotation_file_name=None,\n",
    "    ignore_negative_samples=False,\n",
    "    output_dir=os.path.join(slice_path, 'train'),\n",
    "    slice_height=512,\n",
    "    slice_width=512,\n",
    "    overlap_height_ratio=0.2,\n",
    "    overlap_width_ratio=0.2,\n",
    "    min_area_ratio=0.1,\n",
    "    verbose=False\n",
    ")\n",
    "save_json(train_sliced_coco_dict, os.path.join(slice_path, 'train', '_annotations.coco.json'))\n",
    "\n",
    "\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('Pt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ab95893a39d844b8a6142fea37f53a33c9327d14535c7612ea18ef4b7bca2ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
